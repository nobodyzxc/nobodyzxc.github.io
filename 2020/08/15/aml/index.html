<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-tw">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-flash.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="UNCALCULABLE LIFE" type="application/atom+xml">






<meta name="description" content="暑假花了一點時間和同學做起來的 project，來場經驗分享吧！">
<meta property="og:type" content="article">
<meta property="og:title" content="玉山 NLP 應用挑戰賽">
<meta property="og:url" content="http://nobodyzxc.github.io/2020/08/15/aml/index.html">
<meta property="og:site_name" content="UNCALCULABLE LIFE">
<meta property="og:description" content="暑假花了一點時間和同學做起來的 project，來場經驗分享吧！">
<meta property="og:locale" content="zh-tw">
<meta property="og:image" content="https://i.imgur.com/2Jibg8j.png">
<meta property="og:image" content="https://i.imgur.com/0cjPF0C.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-c101ddc3b2f4dbd3dc20999f900c71ba_720w.jpg">
<meta property="og:image" content="https://i.imgur.com/4durE7N.png">
<meta property="og:updated_time" content="2020-08-24T10:28:21.478Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="玉山 NLP 應用挑戰賽">
<meta name="twitter:description" content="暑假花了一點時間和同學做起來的 project，來場經驗分享吧！">
<meta name="twitter:image" content="https://i.imgur.com/2Jibg8j.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://nobodyzxc.github.io/2020/08/15/aml/">





  <title>玉山 NLP 應用挑戰賽 | UNCALCULABLE LIFE</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

<a href="https://github.com/nobodyzxc" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="top-scroll-bar"></div>

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">UNCALCULABLE LIFE</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            關於
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            標籤
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分類
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            歸檔
          </a>
        </li>
      
        
        <li class="menu-item menu-item-wiki">
          <a href="/wiki/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-wikipedia-w"></i> <br>
            
            維基
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            檢索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobodyzxc.github.io/2020/08/15/aml/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="lambda.catノ">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UNCALCULABLE LIFE">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">玉山 NLP 應用挑戰賽</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2020-08-15T21:22:07+08:00">
                2020-08-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Note/" itemprop="url" rel="index">
                    <span itemprop="name">Note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/15/aml/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/08/15/aml/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-eye"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>times
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字數統計&#58;</span>
                
                <span title="字數統計">
                  9k word(s)
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">閱讀時長 &asymp;</span>
                
                <span title="閱讀時長">
                  36 min(s)
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <center>
暑假花了一點時間和同學做起來的 project，來場經驗分享吧！
</center>


<a id="more"></a>
<p><br><br><br>學期末在 FB 上看到有人在人工智慧社團分享了這個比賽，感覺這個議題滿有趣的，剛好大學有修過一門 IR (Information Retrieval, 資訊檢索) 的課，他算是自然語言處理 (NLP) 的應用，所以也算對 NLP 有一點點基本的認識，手上有那時期末 project 做出來的 crawler 和 IR Model，我便拉著同學們一起入坑了。</p>
<p>所有的 code 都已經放在 <a href="https://github.com/BlackBoxOperator/GotchaTheNames" target="_blank" rel="noopener">GitHub</a> 上了，有興趣可以參考，<br>不過因為訓練資料是主辦單位提供，故不能釋出。<br>這部份可能要讀者自行爬取並標記。</p>
<iframe style="overflow:hidden;" scrolling="no" width="100%" height="400" src="https://hackmd.io/@nobodyzxc/BkoH_a-Mv#/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<blockquote>
<p>分享會當天的報告用投影片</p>
</blockquote>
<p>接著就來介紹一下這個比賽吧！</p>
<h2 id="競賽說明-About-Competition"><a href="#競賽說明-About-Competition" class="headerlink" title="競賽說明 About Competition"></a>競賽說明 About Competition</h2><blockquote>
<p>以下說明來自 <a href="https://tbrain.trendmicro.com.tw/Competitions/Details/11" target="_blank" rel="noopener">玉山官網</a> 。</p>
</blockquote>
<p>Gotcha！人人都可以是反洗錢大師！</p>
<p>洗錢是指將犯罪不法所得，以各種手段掩飾、隱匿而使犯罪所得在形式上合法化的行為。近年來因國際洗錢與資助恐怖活動事件頻傳，國內吸金、電信詐騙案件也層出不窮，使得政府與各產業皆致力於洗錢防制 (AML) 工作。</p>
<p>一般來說，顧客與金融機構往來時，銀行需即時確認顧客身份，透過自動化系統比對出顧客是否列於 AML 焦點人物名單中。若能透過 AI 的協助定期更新 AML 焦點人物名單，並搭配自動化比對，將可大幅降低銀行執行AML作業的人力與時間成本。</p>
<p>本次競賽將提供參賽者公開新聞資料連結與相對應的焦點人物名單，希望大家集思廣益，透過NLP演算法，精準找出 AML 相關新聞焦點人物，不僅能協助優化 AML 焦點人物名單的更新作業，更有機會獲得高額獎金！</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>項目</th>
<th>日期</th>
</tr>
</thead>
<tbody>
<tr>
<td>報名</td>
<td>06/01/2020 - 06/30/2020</td>
</tr>
<tr>
<td>測試賽</td>
<td>07/22/2020</td>
</tr>
<tr>
<td>正式賽</td>
<td>07/27/2020 - 07/30/2020 <br> 08/03/2020 - 08/06/2020</td>
</tr>
<tr>
<td>公布名次</td>
<td>08/12/2020</td>
</tr>
<tr>
<td>頒獎典禮</td>
<td>08/22/2020</td>
</tr>
</tbody>
</table>
</div>
<p>簡單來說，這個比賽就是要判斷一篇文章是不是 AML 相關的新聞，<br>如果是的話，就要把裡面的焦點人物（通常是有犯罪事實的人物）抓出來，生成一個名單。</p>
<p>由於是學期末看到的比賽，比賽已經開始快一個月了，又因為學期末課業繁忙，估計學期結束才能開始。算一算 7/6 才可以開始做，距離測試賽估計只有兩個禮拜，之後離正式賽也只有一個禮拜可以調整模型。不過加上先前的經驗，我想大概夠了，一方面也不想佔用太多時間在比賽上，也就抱著玩玩的心態來嘗試一下、衝刺看看。</p>
<h2 id="爬蟲-Crawling"><a href="#爬蟲-Crawling" class="headerlink" title="爬蟲 Crawling"></a>爬蟲 Crawling</h2><p>有了先前的基礎，基本上只花了一個晚上就把資料都爬回來了。<br>爬蟲是相對容易，但是需要重複性勞動的工作，以下介紹我是怎麼爬新聞的。</p>
<h3 id="Basic-crawling"><a href="#Basic-crawling" class="headerlink" title="Basic crawling"></a>Basic crawling</h3><p>新聞網站大部份是動態網頁，通常是由伺服器端從資料庫撈內文出來套在模板上，<br>然後回傳給 user，所以只要是同個網站的新聞，他們大多會遵照一定的排版。</p>
<h4 id="pandas-amp-the-domains"><a href="#pandas-amp-the-domains" class="headerlink" title="pandas &amp; the domains"></a>pandas &amp; the domains</h4><p>第一步就先來看看有哪些網站的排版要抓，<br>我們先把主辦單位提供給我們的資料透過 pandas 讀進來，接著把所有 domain 讀出來。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">csv = pd.read_csv(<span class="string">'tbrain_train_final_0610.csv'</span>)</span><br><span class="line">webs = set(re.findall(<span class="string">r'(https?://)?([^/]+)'</span>, l)[<span class="number">0</span>][<span class="number">1</span>] <span class="keyword">for</span> l <span class="keyword">in</span> csv[<span class="string">'hyperlink'</span>])</span><br><span class="line">pprint(webs)</span><br></pre></td></tr></table></figure>
<p>可以得到這 39 個 domain：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'ccc.technews.tw'</span>,</span><br><span class="line"> <span class="string">'domestic.judicial.gov.tw'</span>,</span><br><span class="line"> <span class="string">'ec.ltn.com.tw'</span>,</span><br><span class="line"> <span class="string">'ent.ltn.com.tw'</span>,</span><br><span class="line"> <span class="string">'estate.ltn.com.tw'</span>,</span><br><span class="line"> <span class="string">'finance.technews.tw'</span>,</span><br><span class="line"> <span class="string">'hk.on.cc'</span>,</span><br><span class="line"> <span class="string">'house.ettoday.net'</span>,</span><br><span class="line"> <span class="string">'m.ctee.com.tw'</span>,</span><br><span class="line"> <span class="string">'m.ltn.com.tw'</span>,</span><br><span class="line"> <span class="string">'money.udn.com'</span>,</span><br><span class="line"> <span class="string">'mops.twse.com.tw'</span>,</span><br><span class="line"> <span class="string">'news.cnyes.com'</span>,</span><br><span class="line"> <span class="string">'news.ebc.net.tw'</span>,</span><br><span class="line"> <span class="string">'news.ltn.com.tw'</span>,</span><br><span class="line"> <span class="string">'news.mingpao.com'</span>,</span><br><span class="line"> <span class="string">'news.tvbs.com.tw'</span>,</span><br><span class="line"> <span class="string">'ol.mingpao.com'</span>,</span><br><span class="line"> <span class="string">'sina.com.hk'</span>,</span><br><span class="line"> <span class="string">'technews.tw'</span>,</span><br><span class="line"> <span class="string">'tw.news.yahoo.com'</span>,</span><br><span class="line"> <span class="string">'udn.com'</span>,</span><br><span class="line"> <span class="string">'www.bnext.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.businesstoday.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.chinatimes.com'</span>,</span><br><span class="line"> <span class="string">'www.cna.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.coolloud.org.tw'</span>,</span><br><span class="line"> <span class="string">'www.cw.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.ettoday.net'</span>,</span><br><span class="line"> <span class="string">'www.fsc.gov.tw'</span>,</span><br><span class="line"> <span class="string">'www.hbrtaiwan.com'</span>,</span><br><span class="line"> <span class="string">'www.hk01.com'</span>,</span><br><span class="line"> <span class="string">'www.managertoday.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.mirrormedia.mg'</span>,</span><br><span class="line"> <span class="string">'www.nextmag.com.tw'</span>,</span><br><span class="line"> <span class="string">'www.nownews.com'</span>,</span><br><span class="line"> <span class="string">'www.setn.com'</span>,</span><br><span class="line"> <span class="string">'www.storm.mg'</span>,</span><br><span class="line"> <span class="string">'www.wealth.com.tw'</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="beautiful-soup-4-amp-the-selector"><a href="#beautiful-soup-4-amp-the-selector" class="headerlink" title="beautiful soup 4 &amp; the selector"></a>beautiful soup 4 &amp; the selector</h4><p>有了 domain 之後就是重複性的工作了。<br>從各個 domain 中各挑一篇新聞出來查看他的內文位置，然後寫好 selector 用 bs4 抓出來。</p>
<p>舉個例子：<a href="http://finance.technews.tw/2019/09/06/palo-alto-networks-intends-to-acquire-zingbox/" target="_blank" rel="noopener">http://finance.technews.tw/2019/09/06/palo-alto-networks-intends-to-acquire-zingbox/</a></p>
<p>按下 f12 後可以看到，此網頁的 article tag 可以涵蓋所有內文，<br>之後我再把他 p tag 的內容抓出來就好。</p>
<p><img src="https://i.imgur.com/2Jibg8j.png" alt></p>
<p>把 39 個 domain 抓出來大概長這樣：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">fetch_table = &#123;</span><br><span class="line">        <span class="comment"># previous</span></span><br><span class="line">        <span class="string">'www.chinatimes.com'</span>:          [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'article-body'</span>&#125;],</span><br><span class="line">        <span class="string">'news.tvbs.com.tw'</span>:            [<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'news_detail_div'</span>&#125;],</span><br><span class="line">        <span class="string">'home.appledaily.com.tw'</span>:      [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'ncbox_cont'</span>&#125;],</span><br><span class="line"></span><br><span class="line">        <span class="comment"># current</span></span><br><span class="line">        <span class="string">'news.cnyes.com'</span>:              [<span class="string">'div'</span>, &#123;<span class="string">'itemprop'</span>: <span class="string">'articleBody'</span>&#125;],</span><br><span class="line">        <span class="string">'www.mirrormedia.mg'</span>:          [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'domestic.judicial.gov.tw'</span>:    [<span class="string">'pre'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.coolloud.org.tw'</span>:         [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>:<span class="string">'field-items'</span>&#125;],</span><br><span class="line">        <span class="string">'m.ctee.com.tw'</span>:               [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'entry-main'</span>&#125;],</span><br><span class="line">        <span class="string">'mops.twse.com.tw'</span>:            [<span class="string">'div'</span>, &#123;<span class="string">'id'</span>: <span class="string">'zoom'</span>&#125;],</span><br><span class="line">        <span class="string">'www.hk01.com'</span>:                [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.wealth.com.tw'</span>:           [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'entry-main'</span>&#125;],</span><br><span class="line">        <span class="string">'news.ebc.net.tw'</span>:             [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'fncnews-content'</span>&#125;],</span><br><span class="line">        <span class="string">'news.mingpao.com'</span>:            [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.bnext.com.tw'</span>:            [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'content'</span>&#125;],</span><br><span class="line">        <span class="string">'news.ltn.com.tw'</span>:             [<span class="string">'div'</span>, &#123;<span class="string">'itemprop'</span>: <span class="string">'articleBody'</span>&#125;],</span><br><span class="line">        <span class="string">'finance.technews.tw'</span>:         [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.fsc.gov.tw'</span>:              [<span class="string">'div'</span>, &#123;<span class="string">'id'</span>: <span class="string">'maincontent'</span>&#125;],</span><br><span class="line">        <span class="string">'www.cw.com.tw'</span>:               [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.businesstoday.com.tw'</span>:    [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'article'</span>&#125;],</span><br><span class="line">        <span class="string">'sina.com.hk'</span>:                 [<span class="string">'section'</span>, &#123;<span class="string">'id'</span>: <span class="string">'content'</span>&#125;],</span><br><span class="line">        <span class="string">'www.ettoday.net'</span>:             [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'hk.on.cc'</span>:                    [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'breakingNewsContent'</span>&#125;],</span><br><span class="line">        <span class="string">'technews.tw'</span>:                 [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'content'</span>&#125;],</span><br><span class="line">        <span class="string">'money.udn.com'</span>:               [<span class="string">'div'</span>, &#123;<span class="string">'id'</span>: <span class="string">'article_body'</span>&#125;],</span><br><span class="line">        <span class="string">'udn.com'</span>:</span><br><span class="line">        [<span class="string">'div'</span>,                        &#123;<span class="string">'class'</span>: <span class="string">'article-content__paragraph'</span>&#125;],</span><br><span class="line">        <span class="string">'tw.news.yahoo.com'</span>:           [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.setn.com'</span>:                [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.managertoday.com.tw'</span>:     [<span class="string">'body'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.cna.com.tw'</span>:              [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'estate.ltn.com.tw'</span>:           [<span class="string">'div'</span>, &#123;<span class="string">'itemprop'</span>: <span class="string">'articleBody'</span>&#125;],</span><br><span class="line">        <span class="string">'m.ltn.com.tw'</span>:                [<span class="string">'div'</span>, &#123;<span class="string">'itemprop'</span>: <span class="string">'articleBody'</span>&#125;],</span><br><span class="line">        <span class="string">'ccc.technews.tw'</span>:             [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.hbrtaiwan.com'</span>:           [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'article'</span>&#125;],</span><br><span class="line">        <span class="string">'ec.ltn.com.tw'</span>:               [<span class="string">'p'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.nownews.com'</span>:             [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'newsContainer'</span>&#125;],</span><br><span class="line">        <span class="string">'ol.mingpao.com'</span>:              [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'article_wrap'</span>&#125;],</span><br><span class="line">        <span class="string">'tw.nextmgz.com'</span>:              [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'www.nextmag.com.tw'</span>:          [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'ent.ltn.com.tw'</span>:              [<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">'text'</span>&#125;],</span><br><span class="line">        <span class="string">'www.storm.mg'</span>:                [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        <span class="string">'house.ettoday.net'</span>:           [<span class="string">'article'</span>, &#123;&#125;],</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_article_args_by</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> domain <span class="keyword">in</span> fetch_table:</span><br><span class="line">        <span class="keyword">if</span> domain <span class="keyword">in</span> url:</span><br><span class="line">            tag, attr = fetch_table[domain]</span><br><span class="line">            <span class="keyword">return</span> &#123; <span class="string">'name'</span>: tag, <span class="string">'attrs'</span>: attr &#125;</span><br><span class="line">    print(<span class="string">"cannot find domain pattern in"</span>, url)</span><br></pre></td></tr></table></figure></p>
<p>以下使用 bs4 搭配上面我們抓到的資料，進行單篇資料爬取（要將上面的 code 加到下面的 code）</p>
<p>其實在實際狀況有滿多特殊例外需要處理，比如網站沒有回應，需要重新 get，<br>或者一些 general case (比如只取 p tag) 不適用，就要另外再撰寫規則。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests <span class="keyword">as</span> rq</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">add = <span class="keyword">lambda</span> a, b: a + b</span><br><span class="line">resc = <span class="keyword">lambda</span> s: s.replace(<span class="string">"\r"</span>, <span class="string">''</span>).replace(<span class="string">""</span>, <span class="string">""</span>).replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://finance.technews.tw/2019/12/22/tkec-road-to-reform/'</span></span><br><span class="line">html = rq.get(url, timeout = <span class="number">10</span>).text</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">articles = soup.findAll(**find_article_args_by(url))</span><br><span class="line">paragraphs = reduce(add, [a.findChildren(<span class="string">"p"</span>) <span class="keyword">for</span> a <span class="keyword">in</span> articles])</span><br><span class="line">paragraphs += reduce(add, [a.find_all(<span class="string">r'^h[1-6]$'</span>) <span class="keyword">for</span> a <span class="keyword">in</span> articles])</span><br><span class="line">content = resc(<span class="string">' '</span>.join([s <span class="keyword">for</span> s <span class="keyword">in</span> [p.get_text().strip() <span class="keyword">for</span> p <span class="keyword">in</span> paragraphs]]))</span><br><span class="line">print(content)</span><br></pre></td></tr></table></figure>
<p>抓到的文章為：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">台灣 3C 通路龍頭燦坤，一個月之內，董事長、總經理、財務長、發言人接連離職，由老臣陳彥君迅速接任董座，他能否勵精圖治，成功改革老燦坤？  對所有零售通路、電商業而言，11 月是最忙碌的 1 個月，業者</span><br><span class="line">無不打起精神為雙 11 備戰。但是，面對實體、虛擬通路競爭對手兩路夾殺的 3C 通路龍頭燦坤實業，似乎花更多力氣在打一場「內戰」。 先是上任不到 8 個月的總經理李佳峰在 11 月 18 日清晨「因個人規畫」辭</span><br><span class="line">職，今年 5 月甫上任的發言人蔡依玲也同時離開；12 月 12 日，上任一年多的董事長何宗原，以及 2018 年底上任的財務長徐霄菀雙雙離職。一個月之間，上至董事長、下至發言人全面大搬風，燦坤一次折損 4 位專業經理人。 何宗原曾任台灣嬌生業務總監、中國嬌生消費品產品副總裁，2018 年在燦坤創辦人吳燦坤的妻子蔡淑惠引薦下，以專業經理人身分接下燦坤董事長。 何宗原延攬了曾在台灣萊雅、台灣寶僑家品財務部門任職的徐霄菀，以及小米前台灣總經理李佳峰進入燦坤。今年 9 月，燦坤轉投資事業金鑛咖啡、燦星旅遊因虧損擴大裁員，燦坤以何宗原、李佳峰兩人名義共同發布內部信，要「以二次創業的心態共同迎接挑戰」穩定軍心，兩人甚至在 9 月舉辦活動親自向品牌商介紹燦坤的轉型計畫，但隨著兩人先後離職，內部改革似乎戛然而止。 4 位專業經理人接連離去，所為哪樁？也許，財報透露了些許端倪。 燦坤今年前 3 季穩住 3C 通路</span><br><span class="line">龍頭地位，但營收、獲利皆較 2018 年同期衰退，尤其稅後淨利更較 2018 年同期大減 27%；反觀 3C 通路老二全國電子，今年前 3 季營收卻逆勢成長 5%。因此，市場傳言何宗原離去的主因恐與「業績無起色」有關</span><br><span class="line">。 不過，市場也有另外一派說法指出，何的離去可能與李佳峰有關；業界人士指出，李佳峰進入燦坤後的改革計畫獲得董事會授權，但在財務執行方面，卻未取得何宗原、徐霄菀支持，導致無資金奧援的李佳峰選擇掛冠求去，董事會頗為不滿。 但也有接近燦坤的人士指出，身兼燦坤、燦星網通及燦星旅遊董事長的何宗原，花了相當多心力在轉投資金鑛咖啡、燦坤集團旗下負責研發智慧家電的燦坤先端智能，似乎「很少時間花在燦坤」。 根據閩燦坤財報，先端智能 2018 年虧損達 1,216 萬人民幣，而金鑛咖啡將轉型成咖啡豆原物料供應商；燦星旅遊也持續關閉實體店面，顯然都是需要費心的事業體，這些都成了何宗原請辭導火線。 接近燦坤的人士也對記者表示，「燦星旅遊的問題尤其嚴重」，以線上旅遊產品起家，轉往實體店舖經營的燦星旅遊，自 2015 年起總共虧損 3.73 億元；從 2018 年何接任董事長以後，帳上現金從 2018 年第三季的 3.43 億</span><br><span class="line">元到今年第三季只剩下 1 億元。 旅遊業者指出，燦星雖然試圖反攻實體店，但最後功敗垂成，其他旅行社逐漸走向精緻化路線經營時，燦星沒有追上這股潮流，該業者表示：「業界對他們的觀感，就是成本壓得非常</span><br><span class="line">低，品質也不好。」 只是，就在眾人還未反應過來時，12 月 13 日，燦坤火速召開董事會，選出老臣陳彥君新任燦坤董事長。 陳彥君十多年前就在燦坤任職，曾任發言人、財務長、風控長及財務總經理，雖曾短暫到特力和樂擔任副董事長，最後又回到燦坤體系，擔任燦星網通、燦星旅遊董事長，頗受吳燦坤夫婦信任。 （作者：王子承；全文未完，完整內容請見《今周刊》） 科技新知，時時更新 30 天內走了 4 個高階經理人，燦坤改革之路恐遇逆風？ 高層求去，財報透端倪？ 延伸閱讀：</span><br></pre></td></tr></table></figure></p>
<h3 id="Advenced-crawling"><a href="#Advenced-crawling" class="headerlink" title="Advenced crawling"></a>Advenced crawling</h3><h4 id="wayback-machine-amp-the-missing-pages-404"><a href="#wayback-machine-amp-the-missing-pages-404" class="headerlink" title="wayback machine &amp; the missing pages (404)"></a>wayback machine &amp; the missing pages (404)</h4><p>對於一些 404 的網頁，我們可以想辦法把他找回來，<br>比方說 wayback machine 就是一個不錯的選擇。</p>
<p>我是用別人寫好的這個 <a href="https://github.com/jsvine/waybackpack" target="_blank" rel="noopener">waybackpack</a>，也是 python 寫的小工具，<br>他只依賴 requests 這個額外的套件。</p>
<p>裝起來也很簡單：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install waybackpack</span><br></pre></td></tr></table></figure>
<p>使用範例就大概是這樣：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">waybackpack -d wayback https://udn.com/news/story/7321/3845624</span><br></pre></td></tr></table></figure></p>
<p><code>-d</code> 是資料夾，他會自動創一個你指定名字的資料夾，然後把資料存進去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">waybackpack -d wayback https://udn.com/news/story/7321/3845624</span><br><span class="line">waybackpack -d wayback https://udn.com/news/story/7321/3833161</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ tree -ifF wayback | grep -v &apos;/$&apos;</span><br><span class="line"></span><br><span class="line">wayback</span><br><span class="line">wayback/20190524225425/udn.com/news/story/7321/3833161</span><br><span class="line">wayback/20190608120835/udn.com/news/story/7321/3845624</span><br><span class="line">wayback/20190609133509/udn.com/news/story/7321/3845624</span><br><span class="line">wayback/20190827225620/udn.com/news/story/7321/3845624</span><br><span class="line"></span><br><span class="line">20 directories, 4 files</span><br></pre></td></tr></table></figure>
<p>之後就是開個檔，然後一樣餵給剛剛寫的 crawler 即可。<br>（把 <code>requests.get(url)</code> 改成 <code>open(path)</code>，然後 <code>.text</code> 改 <code>.read()</code>）</p>
<p>如果連 wayback machine 都沒有，那就手動丟搜尋引擎吧！<br>或許有人轉載，還留著一些資料。</p>
<h4 id="requests-html-amp-the-dynamic-pages-ajax"><a href="#requests-html-amp-the-dynamic-pages-ajax" class="headerlink" title="requests-html &amp; the dynamic pages (ajax)"></a>requests-html &amp; the dynamic pages (ajax)</h4><p>此次比賽給的網頁似乎沒有此種頁面，但這邊還是提一下。</p>
<p>有時候動態生成不是由伺服端做，而是在客戶端使用 ajax 請求內文，然後套進框架。<br>這時候就要使用瀏覽器 js 引擎去渲染，而在 python 就必須使用額外的工具來做。</p>
<p>例如自由時報娛樂版是採動態生成內文，<br>這部份可以使用 <a href="https://github.com/oldani/requests-html" target="_blank" rel="noopener">requests-html</a> 這個 library。</p>
<p>只用方法不難，只要照著他的 <code>README.md</code> 就可以了，在此就不贅述了。</p>
<h2 id="模型雛型-Naive-Model"><a href="#模型雛型-Naive-Model" class="headerlink" title="模型雛型 Naive Model"></a>模型雛型 Naive Model</h2><p>根據要求，我們不難設想到這個模型大概可以分成兩個部份。</p>
<ol>
<li>classifier 用來辨別是否為 AML 新聞。</li>
<li>extractor 用來提取目標人名。</li>
</ol>
<p>以下就來介紹一下我們一開始是怎麼實作這兩個工具的。</p>
<h3 id="Document-Classification"><a href="#Document-Classification" class="headerlink" title="Document Classification"></a>Document Classification</h3><p>要把文件分兩類，首先就必須想到何謂分類。<br>一般來說，分到同一類的東西，他們彼此的相似度會比較高，<br>所以應用這個概念，我們只要能算出文章的相似度就可以達到分類的目標。</p>
<p>那該怎麼判斷兩篇文章的相似度呢？</p>
<p>我們先來探討一下詞和文章的關係。</p>
<p>那考慮把所有新聞出現過的詞想做一個集合，或者把他想成一個向量的形式。</p>
<p>比如這裡有三句話，我們把他當成三篇文章，為一個 corpus，並且已經做好斷詞。</p>
<ol>
<li>太平洋/有/颱風/生成/，/請/民眾/關注/天氣/，/嚴防/大雨/。</li>
<li>天氣/預報/：/氣流/影響/，/天氣/仍舊/不穩/，/留意/瞬間/大雨/。</li>
<li>台灣/座落/於/西/太平洋/。</li>
</ol>
<p>斷詞在實作上我們是使用 <a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">jieba</a> 的 <code>search_mode</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">text = <span class="string">'台灣座落於西太平洋。'</span></span><br><span class="line"></span><br><span class="line">print(jieba.lcut_for_search(text))       <span class="comment"># 搜尋引擎模式</span></span><br><span class="line"><span class="comment"># ['台灣', '座落', '於', '太平', '太平洋', '西太平洋', '。']</span></span><br><span class="line"></span><br><span class="line">print(jieba.lcut(text, cut_all = <span class="literal">True</span>))  <span class="comment"># 全模式</span></span><br><span class="line"><span class="comment"># ['台', '灣', '座落', '於', '西太平洋', '太平', '太平洋', '', '']</span></span><br><span class="line"></span><br><span class="line">print(jieba.lcut(text, cut_all = <span class="literal">False</span>)) <span class="comment"># 精確模式（如沒指定 cut_all 則為默認）</span></span><br><span class="line"><span class="comment"># ['台灣', '座落', '於', '西太平洋', '。']</span></span><br></pre></td></tr></table></figure>
<p>把停用詞 (stopword) 等一些常用的詞去掉，例如 <code>請</code>，<code>於</code>, <code>仍舊</code>, <code>瞬間</code> 一類的詞，所有詞可以表示成一個 vector。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[太平洋, 颱風, 生成, 民眾, 關注, 天氣, 嚴防, 大雨, 預報, 氣流, 影響, 不穩, 留意, 台灣, 座落]</span><br></pre></td></tr></table></figure>
<p>去掉停用詞的新文章為：</p>
<ol>
<li>太平洋/颱風/生成/民眾/關注/天氣/嚴防/大雨</li>
<li>天氣/預報/氣流/影響/天氣/不穩/留意/大雨</li>
<li>台灣/座落/太平洋</li>
</ol>
<p>不難想到，一個詞如果在一篇文章中出現多次，那這個詞和這篇文章的關聯度就會越高，這個就是 TF (term frequency) 的概念，一般可以計算為 <code>該詞出現在該文章的次數 / 該篇文章的詞數</code>。該文章的詞數為正規化的用途，避免文章過長導致某詞的頻率過高。一篇文章的 TF vector 可以當成一種特徵值。以下為三篇文章的 TF vector。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[太平洋, 颱風, 生成, 民眾, 關注, 天氣, 嚴防, 大雨, 預報, 氣流, 影響, 不穩, 留意, 台灣, 座落]</span><br><span class="line">[  <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,  <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,  <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>]</span><br><span class="line">[    <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">2</span>/<span class="number">8</span>,   <span class="number">0</span>, <span class="number">1</span>/<span class="number">8</span>,  <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,  <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,   <span class="number">0</span>,    <span class="number">0</span>]</span><br><span class="line">[  <span class="number">1</span>/<span class="number">3</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,    <span class="number">0</span>,   <span class="number">0</span>, <span class="number">1</span>/<span class="number">3</span>,  <span class="number">1</span>/<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>用 TF 的直覺大概就是如果兩篇文章擁有相同的詞越多，那相似度可能就越高。</p>
<p>我們可以用 cosine similarity 來計算三篇文章的相似度：</p>
<script type="math/tex; mode=display">\cos (t,e)= {t e \over \|t\| \| e\|} = \frac{ \sum_{i=1}^{n}{t_i e_i} }{ \sqrt{\sum_{i=1}^{n}{(t_i)^2} } \sqrt{\sum_{i=1}^{n}{(e_i)^2} } }</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">vecA = [<span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>]</span><br><span class="line">vecB = [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">2</span>/<span class="number">8</span>,   <span class="number">0</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>,   <span class="number">0</span>,   <span class="number">0</span>]</span><br><span class="line">vecC = [<span class="number">1</span>/<span class="number">3</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">1</span>/<span class="number">3</span>, <span class="number">1</span>/<span class="number">3</span>]</span><br><span class="line">print(cosine_similarity([vecA, vecB, vecC], [vecA, vecB, vecC]))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a          b          c</span></span><br><span class="line">[[<span class="number">1.</span>         <span class="number">0.3354102</span>  <span class="number">0.20412415</span>]  <span class="comment"># a</span></span><br><span class="line"> [<span class="number">0.3354102</span>  <span class="number">1.</span>         <span class="number">0.</span>        ]  <span class="comment"># b</span></span><br><span class="line"> [<span class="number">0.20412415</span> <span class="number">0.</span>         <span class="number">1.</span>        ]] <span class="comment"># c</span></span><br></pre></td></tr></table></figure>
<p>而更進一步考慮，一個詞他在只出現在某幾篇新聞中（比如 “洗錢”）和一個詞幾乎每篇都有（比如 “記者”），那前者的重要性和獨特性應該會比後者高。這就是 IDF（inverse document frequency，逆向文件頻率）的概念，一般計算為 <code>log(所有的文章數目 / (出現該詞的文章數 + 1))</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log(<span class="number">3</span> / (<span class="number">2</span>)) = <span class="number">0.4</span> <span class="comment"># 這邊因為 corpus 小，而且詞都有出現，所以就不做 + 1 避免分母為零</span></span><br><span class="line">log(<span class="number">3</span> / (<span class="number">1</span>)) = <span class="number">1.1</span></span><br><span class="line">[太平洋, 颱風, 生成, 民眾, 關注, 天氣, 嚴防, 大雨, 預報, 氣流, 影響, 不穩, 留意, 台灣, 座落]</span><br><span class="line">[  <span class="number">0.4</span>, <span class="number">1.1</span>,  <span class="number">1.1</span>, <span class="number">1.1</span>, <span class="number">1.1</span>,  <span class="number">0.4</span>, <span class="number">1.1</span>, <span class="number">0.4</span>,  <span class="number">1.1</span>, <span class="number">1.1</span>, <span class="number">1.1</span>,  <span class="number">1.1</span>, <span class="number">1.1</span>, <span class="number">1.1</span>,  <span class="number">1.1</span>]</span><br></pre></td></tr></table></figure>
<p>IDF 可以表達出一個詞的特徵值，我們把他與 TF 相乘，便可得到更有意義的特徵值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[太平洋, 颱風, 生成, 民眾, 關注, 天氣, 嚴防, 大雨, 預報, 氣流, 影響, 不穩, 留意, 台灣, 座落]</span><br><span class="line">[ <span class="number">0.05</span>, <span class="number">0.21</span>,<span class="number">0.21</span>,<span class="number">0.21</span>,<span class="number">0.21</span>, <span class="number">0.05</span>,<span class="number">0.21</span>, <span class="number">0.05</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>]</span><br><span class="line">[  <span class="number">0.0</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.05</span>,<span class="number">0.21</span>,<span class="number">0.21</span>, <span class="number">0.21</span>,<span class="number">0.21</span>,<span class="number">0.21</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>]</span><br><span class="line">[ <span class="number">0.13</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,  <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,<span class="number">0.55</span>, <span class="number">0.55</span>]</span><br></pre></td></tr></table></figure>
<p>我們一樣計算 cosine similarity 可得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a          b          c</span></span><br><span class="line">[[<span class="number">1.</span>         <span class="number">0.03368042</span> <span class="number">0.01800272</span>]  <span class="comment"># a</span></span><br><span class="line"> [<span class="number">0.03368042</span> <span class="number">1.</span>         <span class="number">0.</span>        ]  <span class="comment"># b</span></span><br><span class="line"> [<span class="number">0.01800272</span> <span class="number">0.</span>         <span class="number">1.</span>        ]] <span class="comment"># c</span></span><br></pre></td></tr></table></figure>
<h4 id="BM25-w2v-IR-model-as-classifier"><a href="#BM25-w2v-IR-model-as-classifier" class="headerlink" title="BM25 + w2v + IR model as classifier"></a>BM25 + w2v + IR model as classifier</h4><p>IR model 大概就是以上面提到提到的概念，做出的一個搜尋引擎。<br>給定一段文字，他能幫你按照關聯度排序，把關聯度高的文章排到前面。</p>
<p>而我們之前所作的 model 使用的特徵值是 <a href="https://kknews.cc/zh-tw/news/z2gkr4g.html" target="_blank" rel="noopener">bm25</a>，加上 <a href="https://kknews.cc/zh-tw/code/nkjvlm2.html" target="_blank" rel="noopener">word2vector</a> (word2vector 是一種 word embedding 的實作，透過 unsupervised learning 產出，透過類神經網路，藉由鄰近詞算出一個詞的特徵值），最後再做個 Relevance Feedback (精準點來說，是 <a href="https://zh.wikipedia.org/wiki/%E5%85%B3%E8%81%94%E5%8F%8D%E9%A6%88" target="_blank" rel="noopener">盲式反饋</a> ) 來完成 IR 任務。</p>
<p>那如何用這個 model 當作 classifier 呢？<br>可以把主辦單位給的三百多篇 AML 新聞接起來，直接和要預測的文章算相似度，<br>這邊可能就要抓一個相似度的 threshold 來判斷是或不是。</p>
<p>或者我們採取了一個比較簡單的作法，直接利用 IR model，取前三百篇，看這三百篇裡面，主辦單位標記的 AML 文章 recall 是多少。一樣也要取個 threshold。這邊我們大概就用三百篇和其他非 AML 相關新聞的 recall 下去抓，其實已經有不錯的分類能力了，不過還是有些新聞，例如大樂透開獎會歸進 AML 新聞。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query29: 【2019理財大事5】跌破...</span><br><span class="line">[ x  11 / 300 = 0.036667 score =   5.58 ] Query30: 公開資訊觀測站...</span><br><span class="line">[ v 223 / 300 = 0.743333 score = 195.94 ] Query31: 涉貪圖利 東檢聲押前台...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query32: 昂山素姬明出席國際法 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query33: 繼思想改造集中營之後 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query34: 山頂纜車機件故障暫停 ...</span><br><span class="line">[ v 251 / 300 = 0.836667 score = 215.47 ] Query35: 直銷妹誆「1年帶你住帝...</span><br><span class="line">[ v 262 / 300 = 0.873333 score = 224.46 ] Query36: 潤寅詐貸案延燒 上市公...</span><br><span class="line">[ v 206 / 300 = 0.686667 score = 179.18 ] Query37: 花蓮縣3議員涉收賄 貪 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query38: 週三晚起東北季風增強 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query39: 「灰天鵝」拉警報 | An...</span><br><span class="line">[ x   1 / 300 = 0.003333 score =   0.61 ] Query40: 柯媽爆料：柯文哲絕對 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query41: 媒體：特朗普涉嫌威脅 ...</span><br><span class="line">[ x   0 / 300 = 0.000000 score =   0.00 ] Query42: 國銀海外投資豐收 8月O...</span><br></pre></td></tr></table></figure>
<h3 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a>Named Entity Recognition</h3><p>人名提取是本次比賽的重點。<br>在 NLP 中 Named Entity Recognition 可以識別出特殊的名詞，例如人物、組織和地點等。</p>
<h4 id="NN-model-ckip-rule-based-as-extractor-NER"><a href="#NN-model-ckip-rule-based-as-extractor-NER" class="headerlink" title="NN model (ckip) + rule based as extractor (NER)"></a>NN model (ckip) + rule based as extractor (NER)</h4><p>而在去年九月，中研院的 ckip 開源了一套新的斷詞系統 <a href="https://github.com/ckiplab/ckiptagger" target="_blank" rel="noopener">ckiptagger</a>，與舊的不同處在於這一套是用深度學習的方法，利用 BiLSTM 訓練出來的模型。他一樣利用 pre-training 的 word embedding，然後搭配 BiLSTM 訓練出一套斷詞系統。而後透過斷詞出來的結果再加上 word embedding 訓練出詞性標注。</p>
<p>而最後最重要的 NER 也是由 BiLSTM 訓練而成，需要拿前面的 word embedding + 斷詞結果 + 詞性標注當作輸入。有了這一整套系統，我們就有基本的中文 NER 可以用了。這套斷詞系統相當精確，也有許多類別，地點、組織等都會標記出來，我們只要取用人物的部份即可。</p>
<p>不過人物的部份，他會連一些簡稱（張嫌、陳婦）都標記出來，<br>所以我們這邊會做一個簡單的 filter 去過濾這些結果。</p>
<p>ckiptagger 的版本需求：</p>
<ul>
<li>python&gt;=3.6</li>
<li>tensorflow&gt;=1.13.1,<2 tensorflow-gpu>=1.13.1,&lt;2 (one of them)</2></li>
<li>gdown (optional, for downloading model files from google drive)</li>
</ul>
<p>記得要先載他 train 好的 model 才可以使用，<br>你可以用上面的 gdown 或者直接從載點下載，詳情請參照 <a href="https://github.com/ckiplab/ckiptagger" target="_blank" rel="noopener">ckiptagger</a>。</p>
<p>我們這邊使用的配置如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ckiptagger==<span class="number">0.1</span><span class="number">.1</span></span><br><span class="line">tensorflow-gpu==<span class="number">1.15</span></span><br></pre></td></tr></table></figure></p>
<p>一個簡單的範例片段：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ckiptagger <span class="keyword">import</span> WS, POS, NER</span><br><span class="line">ckipt_data = <span class="string">'ckip'</span> <span class="comment"># ckip pre-training path</span></span><br><span class="line">doc = <span class="string">'重判12年又加保3億，法官怕中電前董周麗真逃亡。'</span></span><br><span class="line">ws = WS(ckipt_data)</span><br><span class="line">pos = POS(ckipt_data)</span><br><span class="line">ner = NER(ckipt_data)</span><br><span class="line">word_s = ws([doc],</span><br><span class="line">            sentence_segmentation=<span class="literal">True</span>,</span><br><span class="line">            segment_delimiter_set=&#123;</span><br><span class="line">                <span class="string">'?'</span>, <span class="string">'？'</span>, <span class="string">'!'</span>, <span class="string">'！'</span>, <span class="string">'。'</span>,</span><br><span class="line">                <span class="string">','</span>,<span class="string">'，'</span>, <span class="string">';'</span>, <span class="string">':'</span>, <span class="string">'、'</span>&#125;)</span><br><span class="line">word_p = pos(word_s)</span><br><span class="line">word_n = ner(word_s, word_p)</span><br><span class="line">namelist = set([e[<span class="number">3</span>] <span class="keyword">for</span> e <span class="keyword">in</span> word_n[<span class="number">0</span>] <span class="keyword">if</span> e[<span class="number">2</span>] == <span class="string">'PERSON'</span>])</span><br><span class="line"></span><br><span class="line">print(namelist) <span class="comment"># &#123;'周麗真'&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>至此，一個不太精確的標記系統已經完成了，<br>此比賽模型也已經有了一個雛型。<br>接下來就講講如何把他接上 API，提供服務給外界使用。</p>
<h2 id="服務建置-Service"><a href="#服務建置-Service" class="headerlink" title="服務建置 Service"></a>服務建置 Service</h2><p>主辦單位提供了 Azure 雲端給我們使用，<br>主要有用的東西除了一個 Ubuntu 可以使用外，還有 K80 的 GPU 及一個 IP。</p>
<p>不過原則上還是自己配的環境好用些。</p>
<h3 id="flask"><a href="#flask" class="headerlink" title="flask"></a>flask</h3><p>主辦單位提供了一個簡易的 flask 模板給我們使用。<br>裡面有強調一點，回傳的 encoding 必須為 UTF-8，<br>只要在 <code>app.run</code> 前更改一下 flask 的 config 即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app.config[<span class="string">'JSON_AS_ASCII'</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>API call 分作兩個部份 health check 和 inference，<br>health check 主要在確認 service availability，而 inference 主要是負責答案的判定。</p>
<p>health check:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/healthcheck', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">healthcheck</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">""" API for health check """</span></span><br><span class="line">    data = request.get_json(force=<span class="literal">True</span>)</span><br><span class="line">    print(data)</span><br><span class="line">    t = datetime.datetime.now()</span><br><span class="line">    ts = str(int(t.utcnow().timestamp()))</span><br><span class="line">    server_uuid = generate_server_uuid(CAPTAIN_EMAIL+ts)</span><br><span class="line">    server_timestamp = t.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;</span><br><span class="line">       <span class="string">'esun_uuid'</span>: data[<span class="string">'esun_uuid'</span>],</span><br><span class="line">       <span class="string">'server_uuid'</span>: server_uuid,</span><br><span class="line">       <span class="string">'captain_email'</span>: CAPTAIN_EMAIL,</span><br><span class="line">       <span class="string">'server_timestamp'</span>: server_timestamp</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure></p>
<p>inference:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">answer_cache = &#123;&#125;</span><br><span class="line"><span class="meta">@app.route('/inference', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">""" API that return your model predictions when E.SUN calls this API """</span></span><br><span class="line">    data = request.get_json(force=<span class="literal">True</span>)</span><br><span class="line">    esun_timestamp = data[<span class="string">'esun_timestamp'</span>] <span class="comment">#自行取用</span></span><br><span class="line">    server_timestamp = datetime.datetime.now().strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br><span class="line"></span><br><span class="line">    ts = str(int(datetime.datetime.now().utcnow().timestamp()))</span><br><span class="line">    server_uuid = generate_server_uuid(CAPTAIN_EMAIL+ts)</span><br><span class="line"></span><br><span class="line">    answer_template = <span class="keyword">lambda</span> ans: jsonify(&#123;</span><br><span class="line">            <span class="string">'esun_timestamp'</span>: data[<span class="string">'esun_timestamp'</span>],</span><br><span class="line">            <span class="string">'server_uuid'</span>: server_uuid,</span><br><span class="line">            <span class="string">'answer'</span>: ans,</span><br><span class="line">            <span class="string">'server_timestamp'</span>: server_timestamp,</span><br><span class="line">            <span class="string">'esun_uuid'</span>: data[<span class="string">'esun_uuid'</span>]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data[<span class="string">'esun_uuid'</span>] <span class="keyword">in</span> cache_answer:</span><br><span class="line">        <span class="keyword">if</span> cache_answer[data[<span class="string">'esun_uuid'</span>]] != <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> answer_template(cache_answer[data[<span class="string">'esun_uuid'</span>]])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">while</span> cache_answer[data[<span class="string">'esun_uuid'</span>]] == <span class="literal">None</span>:</span><br><span class="line">                sleep(<span class="number">4</span>)</span><br><span class="line">            <span class="keyword">return</span> answer_template(cache_answer[data[<span class="string">'esun_uuid'</span>]])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cache_answer[data[<span class="string">'esun_uuid'</span>]] = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            log(data[<span class="string">'news'</span>])</span><br><span class="line">            answer = predict(data[<span class="string">'news'</span>])</span><br><span class="line">            log(answer)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            log(<span class="string">'model error'</span>)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Model error.'</span>)</span><br><span class="line"></span><br><span class="line">        cache_answer[data[<span class="string">'esun_uuid'</span>]] = answer</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> answer_template(answer)</span><br></pre></td></tr></table></figure></p>
<p>從上面的 code 可以發現，我們在 inference 做了 cache，<br>原因是一個 inference 時間上限為五秒，逾時就會重新發 request 過來，次數上限為三次。</p>
<p>為了避免逾時而重複 inference，所以我們做了 cache。<br>不過 inference 通常滿快的，一兩秒內就可以算完了。</p>
<h3 id="static-IP"><a href="#static-IP" class="headerlink" title="static IP"></a>static IP</h3><p>Azure 對外不開放 80 和 443 以外的 port，所以原則上把服務開在其中一個 port 即可。</p>
<p>那如果手上有比較好的顯卡，覺得 K80 跑得太慢，但該電腦又沒有固定 IP 的話怎麼辦呢？</p>
<p>這時可以使用 ssh port forwarding 的功能，forwarding 分作兩種，正向代理和反向代理。正向代理是將伺服器端的 port forward 到我們的電腦上，所以我們可以把伺服器端的服務拿到我們客戶端的 port 來用。反過來想，今天我們是要把我們客戶端提供的服務放到伺服器上，所以用的是反向代理，假設我們把 flask 開在 8080 port 上，那只要 forward 到伺服器的 80 port 上，那外面的人只要用 http protocol 瀏覽伺服器的 IP 位置即可。</p>
<p>值得注意的一點是，<code>/etc/ssh/sshd_config</code> 裡面的 <code>AllowTcpForwarding</code> 必須是 <code>yes</code>，才可以 forward。<br>剛改完記得要重啟 ssh server。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart sshd.service</span><br></pre></td></tr></table></figure>
<p>然後因為 ssh 容易掉，我這邊使用 autossh 讓他自動重連就穩多了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">autossh -M 20000 -i ~/.ssh/id_rsa -NfR  :8080:localhost:8080 user@azure</span><br><span class="line"># foward local 8080 to remote 8080</span><br></pre></td></tr></table></figure>
<p>可以看到，我將本機端的 8080 port forward 到遠端的 8080 port，<br>因為遠端的 80 port 需要 root 權限，但有時 ssh 會關掉 root 遠端登入（只允許 console）。<br>所以這邊可以透過 <a href="https://github.com/vinodpandey/python-port-forward" target="_blank" rel="noopener">python-port-forward</a>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo python2.7 port-forward.py 80:localhost:8080</span><br></pre></td></tr></table></figure>
<p>將 8080 port 再 forward 到 80 port，我們就可以使用 azure 的 IP 了。</p>
<p>原則上有靜態 IP，有 ssh 的 server 都可以使用 forwading，<br>像這次比賽基本上都是由家中 NAS 提供服務。</p>
<h3 id="slack"><a href="#slack" class="headerlink" title="slack"></a>slack</h3><p>前置作業都完成後，只要把 web hook 掛給官方提供的 slack bot 即可。之後比賽他就會去戳你給的 IP address 了。</p>
<p><img src="https://i.imgur.com/0cjPF0C.png" alt></p>
<p>到這邊，已經可以開始拿做好的東西打一場比賽了。<br>接下來讓我們繼續把 model 調得更好！</p>
<h2 id="基本模型-Basic-Model"><a href="#基本模型-Basic-Model" class="headerlink" title="基本模型 Basic Model"></a>基本模型 Basic Model</h2><h3 id="Logistic-Regression-SVM-and-XGBoost"><a href="#Logistic-Regression-SVM-and-XGBoost" class="headerlink" title="Logistic Regression, SVM and XGBoost"></a>Logistic Regression, SVM and XGBoost</h3><p>前面提到的 classifier 作法相對簡單，而準確度有待加強。<br>直接拿所有 AML 文章相似度排名取 threshold 分類還是太粗糙。</p>
<p>這裡我們使用 sklearn 裡面一些比較正式一點的分類器，<br>用剛剛做出來的 bm25 + w2v feature 表示一篇文章拿來做分類。<br>詳細教學可以參考 <a href="https://zhuanlan.zhihu.com/p/50657430" target="_blank" rel="noopener">這篇文章</a>。</p>
<p>我們嘗試了三種分類器：LogisticRegression（羅吉斯回歸），SVC （SVM 分類器）還有 XGBoost。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">clf = LogisticRegression(C=<span class="number">1.0</span>,solver=<span class="string">'lbfgs'</span>,multi_class=<span class="string">'multinomial'</span>)</span><br><span class="line">clf.fit(xtrain_tfv, ytrain)</span><br><span class="line">predictions = clf.predict_proba(xvalid_tfv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clf = SVC(C=<span class="number">1.0</span>, probability=<span class="literal">True</span>) <span class="comment"># since we need probabilities</span></span><br><span class="line">clf.fit(xtrain_svd_scl, ytrain)</span><br><span class="line">predictions = clf.predict_proba(xvalid_svd_scl)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clf = xgb.XGBClassifier(max_depth=<span class="number">7</span>, n_estimators=<span class="number">200</span>, colsample_bytree=<span class="number">0.8</span>,</span><br><span class="line">                        subsample=<span class="number">0.8</span>, nthread=<span class="number">10</span>, learning_rate=<span class="number">0.1</span>)</span><br><span class="line">clf.fit(xtrain_tfv.tocsc(), ytrain)</span><br><span class="line">predictions = clf.predict_proba(xvalid_tfv.tocsc())</span><br></pre></td></tr></table></figure>
<p>這裡 classifier 的準確率來到了 88% 到 90% ，而大樂透類的新聞也被準確歸類了。</p>
<h4 id="BM25-XGBoost-as-classifier"><a href="#BM25-XGBoost-as-classifier" class="headerlink" title="BM25 + XGBoost as classifier"></a>BM25 + XGBoost as classifier</h4><p>經由測試，XGBoost 的效果是最好的，於是我們就把 classifier 換成 XGBoost。</p>
<h4 id="NN-model-ckip-XGBoost-rule-based-as-extractor-NER"><a href="#NN-model-ckip-XGBoost-rule-based-as-extractor-NER" class="headerlink" title="NN model (ckip) + XGBoost + rule based as extractor (NER)"></a>NN model (ckip) + XGBoost + rule based as extractor (NER)</h4><p>另外，因為比賽要求是要有 AML 犯罪相關事實的嫌疑人，所以原先採取的把所有人名都噴出來的作法或許可以再細緻化。這裡我們將一個人名前後五個 token 的 BM25 分數加起來丟給 XGBoost 去分類，接著再丟給一開始的 rule based 來優話我們的目標人名提取器。</p>
<h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><p>在資訊檢索的課程中，教授有提到 BERT 這個神器，但我們在之前的 project 並沒有嘗試。<br>相較於 IR Task 那種大量文本的處理，BERT 比較適合小文本的任務，<br>這次的比賽就是一個非常好的發揮空間，所以我們在此次比賽也開始了對 BERT 的初次嘗試。</p>
<p>因為先前傳統機器學習方法如 BM25, TF 之類的是用 one-hot encoding 的方法，存在特徵稀疏的問題，word embedding 相應而生。他將一個詞映射到一個低維稠密的語義空間，使相似詞可以共享上下文資訊，提升泛化能力。深度學習在近幾年來快速發展，像是前面提到的 word2vector 還有後面開源的 ckip 斷詞工具都有利用到 word embedding。這類工具主要架構大多是用 unsupervised learning 訓練每一個詞的 word embedding，這其實就是在做一個特徵提取的動作，<br>接著再確定想要的任務，例如 ckip 的斷詞或是詞性標記、NER 等，使用先前訓練出來的 embedding 作為表達式，再做一次 supervised learning 讓他更加確定需要的上下文關係，來建立最終的 Model。</p>
<p>根據這種模式，近幾年來發展出了像是 ELMo、OpenAI 的 GPT、Google 的 BERT 及一堆他的變形、其他像是 CMU 的 XLNet 等。訓練 word embedding 從一開始的 RNN 到 LSTM 最後到 Attention，更多原理細節可以參考 <a href="https://www.jishuwen.com/d/2M6u/zh-tw" target="_blank" rel="noopener">這一篇介紹</a>。</p>
<p>我們在測試賽之前嘗試使用 BERT 建立一個新的 classifier，準確度有大幅的提昇。</p>
<h4 id="NN-model-BERT-as-classifier"><a href="#NN-model-BERT-as-classifier" class="headerlink" title="NN model (BERT) as classifier"></a>NN model (BERT) as classifier</h4><p>BERT 的使用也相當容易，python 有一個集 NLP 大成的套件庫叫做 <code>transformers</code>，<br>裡面不僅有 BERT， 也有 XLNet 等 model 。</p>
<p>要下載 BERT 的 pre-training 相當容易，只要把填好 pre-training 的名稱，<br>他跑下去發現沒有的話，就會自己去載了。</p>
<p>至於有哪些 pre-training，除了上網 Google 外，基本上可以來 <a href="https://huggingface.co/models" target="_blank" rel="noopener">hugface 的網站</a> 上面找，<br>因為此次是中文的比賽，所以我們使用了最基本款 <code>bert-base-chinese</code> 即可。</p>
<p>基本上 BERT 的使用細節都可以透過這篇 <a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" target="_blank" rel="noopener">進擊的 BERT：NLP 界的巨人之力與遷移學習</a> 學到，<br>裡面也有範例程式碼，學習起來算是相當的容易。</p>
<p>而原理可參考李宏毅教授的 <a href="https://www.youtube.com/watch?v=UYPa347-DdE" target="_blank" rel="noopener">BERT 的教學影片</a>。</p>
<p>BERT 提供了四大下游任務（就是四個 supervised 的 NN Model），我們可以根據我們的需求，<br>選用適合的任務模型來使用。關於更詳細的四大任務介紹可以參考這篇 <a href="https://zhuanlan.zhihu.com/p/102208639" target="_blank" rel="noopener">知乎專欄</a></p>
<ul>
<li>BertForSequenceClassification：下圖的 (a) 和 (b)，只差在一個 <code>[SEP]</code>，可以用作分類。</li>
<li>BertForMultipleChoice：根據問題，可以從多個選項中選擇一個最佳的答案。</li>
<li>BertForQuestionAnswering：下圖 (c)，用作閱讀理解，可以根據問題標出文章中的答案。</li>
<li>BertForTokenClassification：下圖 (d)，可以為每個 token 做分類，適用於 NER 任務等標記。</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-c101ddc3b2f4dbd3dc20999f900c71ba_720w.jpg" alt="BERT 四大任務"></p>
<p>根據需求，我們使用了 BertForSequenceClassification 做了對單個篇新聞的分類（AML &amp; non-AML），但受限於 BERT 512 的 token size 限制，我們取了文章最後的 510 個 token 丟進 model 。</p>
<p>在 validation data 上的分類準確度從剛才的 90% 直接來到了 99% 。</p>
<p>一個比較基本可以用的 AML 犯罪名單提取系統已經差不多了。<br>時間也來到了測試賽。</p>
<blockquote>
<p>測試賽開始：<br>測試賽僅僅提供測試 server 的穩定度，<br>並沒有提供題目正確答案和分數。</p>
</blockquote>
<h2 id="進階模型-Advenced-Model"><a href="#進階模型-Advenced-Model" class="headerlink" title="進階模型 Advenced Model"></a>進階模型 Advenced Model</h2><p>藉由 BERT，我們的 Model 來到了一個嶄新的境界，<br>想必剛剛各位也有留意到，BERT 也有提供 NER 的任務訓練，<br>而 ckip 的 NER 是用在廣泛用途的，那何不用 BERT 自己也 train 一個呢？</p>
<h3 id="Make-our-NER"><a href="#Make-our-NER" class="headerlink" title="Make our NER"></a>Make our NER</h3><p>根據主辦單位的標記資料，每一篇 AML 文章都有對應的人名集合。</p>
<p>要把資料輸進 BERT 做 NER 還需要把每個 token 做標記。<br>這邊我們根據 <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging" target="_blank" rel="noopener">IOB format</a>，只要把目標人名用 <code>B-PER</code>, <code>I-PER</code> 標起來即可。</p>
<p>首先我們先用 BERT 載入 <code>bert-base-chinese</code>，使用他的 tokenizer 為每篇 AML 新聞做 tokenization。</p>
<p>接著根據幫匹配的人名標上標記，其餘的標上 <code>O</code> 即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;法官怕周麗真逃亡&quot;, [&quot;周麗真&quot;]</span><br><span class="line">[&apos;法&apos;, &apos;官&apos;, &apos;怕&apos;,    &apos;周&apos;,     &apos;麗&apos;,    &apos;真&apos;,&apos;逃&apos;, &apos;亡&apos;]</span><br><span class="line">[&apos;O&apos;,  &apos;O&apos;,  &apos;O&apos;, &apos;B-PER&apos;, &apos;I-PER&apos;, &apos;I-PER&apos;, &apos;O&apos;,  &apos;O&apos;]</span><br></pre></td></tr></table></figure>
<p>只要寫個小小的 script 轉換完資料，<br>接著使用 BertForTokenClassification 就可以開始愉快的 train NER 囉！</p>
<h4 id="NN-model-BERT-as-extractor-NER"><a href="#NN-model-BERT-as-extractor-NER" class="headerlink" title="NN model (BERT) as extractor (NER)"></a>NN model (BERT) as extractor (NER)</h4><p>蠻出乎意料之外的一點是，可能是僅僅標記 AML 目標人物的關係，<br>NER 出來的結果似乎就有了簡單的分類能力，可以避開一些非 AML 相關的人名。<br>所以我們使用 BERT NER 抓出來的結果就不丟進 XGBoost 做分類過濾了。</p>
<p>到這裡，基本的模型已經構建完畢，這就是我們進行正式賽的 Model。</p>
<blockquote>
<p>正式賽分作兩週，共八天。<br>正式賽第一周開始：<br>我們在這週的排名第一天在第四，<br>之後又掉到了五和六。</p>
</blockquote>
<h3 id="Extend-The-DataSet"><a href="#Extend-The-DataSet" class="headerlink" title="Extend The DataSet"></a>Extend The DataSet</h3><h4 id="Reuse-The-IR-Model"><a href="#Reuse-The-IR-Model" class="headerlink" title="Reuse The IR Model"></a>Reuse The IR Model</h4><p>第一周結束的假日，我們用之前的 IR model 將主辦單位標記的三百多篇 AML 新聞當作 query，檢索回相關新聞，並標記了一千五百篇 AML 相關新聞加入 corpus。</p>
<blockquote>
<p>正式賽第二周開始：<br>我們成功爬回了四而隔天又掉回了五，<br>加入一千五百篇的資料似乎有一點提昇。<br>不過 model 似乎還要再加強一下，<br>所以我們決定嘗試其他的 Model。</p>
</blockquote>
<h3 id="Try-other-NN-Model"><a href="#Try-other-NN-Model" class="headerlink" title="Try other NN Model"></a>Try other NN Model</h3><p>我們又嘗試了其他 Model，像是 XLNet, RoBERTa, Albert 等，<br>不過效果似乎並沒有很大的提昇，不知道是不是用法錯誤（比如 XLNet 的 Mask 是 <code>&lt;sep&gt;</code> 而不是 <code>[SEP]</code>），<br>只有 RoBERTa 在 classifier 的表現上的結果有好一些。</p>
<h4 id="NN-model-RoBERTa-as-classifier"><a href="#NN-model-RoBERTa-as-classifier" class="headerlink" title="NN model (RoBERTa) as classifier"></a>NN model (RoBERTa) as classifier</h4><p>最後，經由測試，我們將前幾天的 query 當作 validation set，<br>RoBERTa 的準確度從 96% 上到 97%，RoBERTa 的 classifier 似乎有變好，<br>於是我們將 classifier 換成 RoBERTa。</p>
<p>下圖是我們的最終架構圖：</p>
<p><img src="https://i.imgur.com/4durE7N.png" alt></p>
<blockquote>
<p>由於主辦單位不小心把第七天的 query 送成前一天的，故第七天沒有列入計算。<br>可能是 RoBERTa 的表現加上 1500 的標記資料生效了，最後一天我們的成績跑到了第三名。<br>至此，整個賽程結束。<br>因為我本身的研究領域不是 NLP，加上時間因素，能有這樣的成績已經是相當幸運了。<br>三個禮拜衝刺也到了一段落了 :)</p>
</blockquote>
<h2 id="其他-Others"><a href="#其他-Others" class="headerlink" title="其他 Others"></a>其他 Others</h2><p>除了先前的嘗試，其實我們也有想到一些增強 model 的方法，<br>不過礙於時間關係，我們沒來得及做這些嘗試。</p>
<h3 id="evoluationary-computation"><a href="#evoluationary-computation" class="headerlink" title="evoluationary computation"></a>evoluationary computation</h3><p>我們在嘗試前面的 Model 時，有嘗試用演化計算來調整參數。<br>不過後來 Model 都轉移到 NN 上，我們在傳統機器學習方法上就沒再做更多嘗試了。<br>其實演化計算的應用很廣，或許可以應用在現在 Model 的參數微調上。</p>
<h3 id="other-models"><a href="#other-models" class="headerlink" title="other models"></a>other models</h3><p>其實我們覺得我們 XLNet 以及其他 model 的使用可能不是很正確，所以效果才沒有上來。<br>礙於時間因素及現有其他 model 的網路資源較為缺乏，我們沒來得及做更多嘗試。</p>
<p>或許存在著更棒的 model 也說不定。</p>
<h3 id="improve-the-pre-training-model"><a href="#improve-the-pre-training-model" class="headerlink" title="improve the pre-training model"></a>improve the pre-training model</h3><p>拿將新聞 corpus 繼續做 pre-training 的 unsupervised learning，<br>應該可以加強 pre-training domain specific 的能力，效果也可能因此提昇。</p>
<h3 id="expand-the-data"><a href="#expand-the-data" class="headerlink" title="expand the data"></a>expand the data</h3><p>NER 的部份，也可以將一千五百篇的人名做標記，如此 NER 的效果可能會提昇一些。</p>
<h3 id="data-augmentation"><a href="#data-augmentation" class="headerlink" title="data augmentation"></a>data augmentation</h3><p>跟圖片一樣，NLP 的分類也可以使用 augmentation，<br>這似乎也是一個研究的方向：<a href="https://github.com/zhanlaoban/EDA_NLP_for_Chinese" target="_blank" rel="noopener">一個中文數據增強的實現</a>。</p>

      
    </div>
    
    
    

<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">------------- EOF -------------</div>
    
</div>

  
</div>

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/28/nobody/" rel="next" title="散人">
                <i class="fa fa-chevron-left"></i> 散人
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/11/18/vim-1/" rel="prev" title="Vim Node (Basic Configuration)">
                Vim Node (Basic Configuration) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            本站概覽
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
            <a href="/about/">
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="lambda.catノ">
            
              <p class="site-author-name" itemprop="name">lambda.catノ</p>
            </a>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">文章</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分類</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">標籤</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/nobodyzxc" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://t.me/nobodyzxc" target="_blank" title="Telegram">
                      
                        <i class="fa fa-fw fa-telegram"></i>Telegram</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://incalpcs.blogspot.com" target="_blank" title="Blogger">
                      
                        <i class="fa fa-fw fa-google"></i>Blogger</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.youtube.com/channel/UCPgvp2rLwglsLVCrqVlQXuA" target="_blank" title="YouTube">
                      
                        <i class="fa fa-fw fa-youtube"></i>YouTube</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/nobodyzxc.tw" target="_blank" title="FaceBook">
                      
                        <i class="fa fa-fw fa-facebook"></i>FaceBook</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.instagram.com/nobodyzxc.tw/" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          

          
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
  <div id="myCanvasContainer" class="widget tagcloud">
    <canvas width="220" height="220" id="resCanvas" style="width=100%">
        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/conference/">conference</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/continuation/">continuation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coscup/">coscup</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp/">cpp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cygwin/">cygwin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flolac/">flolac</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fp/">fp</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/game/">game</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/haskell/">haskell</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lambda/">lambda</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lisp/">lisp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logic/">logic</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/oop/">oop</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/opensource/">opensource</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ruby/">ruby</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scheme/">scheme</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sql/">sql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stl/">stl</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a><span class="tag-list-count">2</span></li></ul>
    </canvas>
  </div>
</div>



        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#競賽說明-About-Competition"><span class="nav-number">1.</span> <span class="nav-text">競賽說明 About Competition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#爬蟲-Crawling"><span class="nav-number">2.</span> <span class="nav-text">爬蟲 Crawling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Basic-crawling"><span class="nav-number">2.1.</span> <span class="nav-text">Basic crawling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#pandas-amp-the-domains"><span class="nav-number">2.1.1.</span> <span class="nav-text">pandas &amp; the domains</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#beautiful-soup-4-amp-the-selector"><span class="nav-number">2.1.2.</span> <span class="nav-text">beautiful soup 4 &amp; the selector</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Advenced-crawling"><span class="nav-number">2.2.</span> <span class="nav-text">Advenced crawling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#wayback-machine-amp-the-missing-pages-404"><span class="nav-number">2.2.1.</span> <span class="nav-text">wayback machine &amp; the missing pages (404)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#requests-html-amp-the-dynamic-pages-ajax"><span class="nav-number">2.2.2.</span> <span class="nav-text">requests-html &amp; the dynamic pages (ajax)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型雛型-Naive-Model"><span class="nav-number">3.</span> <span class="nav-text">模型雛型 Naive Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Document-Classification"><span class="nav-number">3.1.</span> <span class="nav-text">Document Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BM25-w2v-IR-model-as-classifier"><span class="nav-number">3.1.1.</span> <span class="nav-text">BM25 + w2v + IR model as classifier</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Named-Entity-Recognition"><span class="nav-number">3.2.</span> <span class="nav-text">Named Entity Recognition</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NN-model-ckip-rule-based-as-extractor-NER"><span class="nav-number">3.2.1.</span> <span class="nav-text">NN model (ckip) + rule based as extractor (NER)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#服務建置-Service"><span class="nav-number">4.</span> <span class="nav-text">服務建置 Service</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#flask"><span class="nav-number">4.1.</span> <span class="nav-text">flask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#static-IP"><span class="nav-number">4.2.</span> <span class="nav-text">static IP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#slack"><span class="nav-number">4.3.</span> <span class="nav-text">slack</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本模型-Basic-Model"><span class="nav-number">5.</span> <span class="nav-text">基本模型 Basic Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic-Regression-SVM-and-XGBoost"><span class="nav-number">5.1.</span> <span class="nav-text">Logistic Regression, SVM and XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BM25-XGBoost-as-classifier"><span class="nav-number">5.1.1.</span> <span class="nav-text">BM25 + XGBoost as classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NN-model-ckip-XGBoost-rule-based-as-extractor-NER"><span class="nav-number">5.1.2.</span> <span class="nav-text">NN model (ckip) + XGBoost + rule based as extractor (NER)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Network"><span class="nav-number">5.2.</span> <span class="nav-text">Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NN-model-BERT-as-classifier"><span class="nav-number">5.2.1.</span> <span class="nav-text">NN model (BERT) as classifier</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#進階模型-Advenced-Model"><span class="nav-number">6.</span> <span class="nav-text">進階模型 Advenced Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Make-our-NER"><span class="nav-number">6.1.</span> <span class="nav-text">Make our NER</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NN-model-BERT-as-extractor-NER"><span class="nav-number">6.1.1.</span> <span class="nav-text">NN model (BERT) as extractor (NER)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Extend-The-DataSet"><span class="nav-number">6.2.</span> <span class="nav-text">Extend The DataSet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Reuse-The-IR-Model"><span class="nav-number">6.2.1.</span> <span class="nav-text">Reuse The IR Model</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Try-other-NN-Model"><span class="nav-number">6.3.</span> <span class="nav-text">Try other NN Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NN-model-RoBERTa-as-classifier"><span class="nav-number">6.3.1.</span> <span class="nav-text">NN model (RoBERTa) as classifier</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他-Others"><span class="nav-number">7.</span> <span class="nav-text">其他 Others</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#evoluationary-computation"><span class="nav-number">7.1.</span> <span class="nav-text">evoluationary computation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#other-models"><span class="nav-number">7.2.</span> <span class="nav-text">other models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#improve-the-pre-training-model"><span class="nav-number">7.3.</span> <span class="nav-text">improve the pre-training model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#expand-the-data"><span class="nav-number">7.4.</span> <span class="nav-text">expand the data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-augmentation"><span class="nav-number">7.5.</span> <span class="nav-text">data augmentation</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lambda.catノ</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">46k </span>
  
</div>










    <script type="text/javascript" src="https://code.jquery.com/jquery-1.10.2.js"></script>
    <script type="text/javascript" src="/files/typed.js"></script>
    <script defer type="text/javascript">
      function load_script(url){
        var ukagaka_script = document.createElement('script');
        ukagaka_script.setAttribute('src', url);
        document.head.appendChild(ukagaka_script);
      }
      function load_style(url){
        var ukagaka_css = document.createElement('link');
        ukagaka_css.setAttribute('rel', 'stylesheet');
        ukagaka_css.setAttribute('type', type='text/css');
        ukagaka_css.setAttribute('href', url);
        document.head.appendChild(ukagaka_css);
      }

      document.onreadystatechange = function () {
          if (document.readyState == "interactive") {
              load_script('/files/reconnecting-websocket.min.js');
              load_style('/files/ukagaka.css');
              load_script('/files/jquery-ui.js');
              //load_script('/files/typed.js');
              load_script('/files/ukagaka.js');
              //load_script('/files/jquery.morris.ukagaka.resource.js');
          }
      }
    </script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      visitors:
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      <i class="fa fa-user"></i>
    </span>
  

  
    <span class="site-pv">
      visit count:
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      🐾
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>











  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/custom.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-nobodyzxc-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://nobodyzxc.github.io/2020/08/15/aml/';
          this.page.identifier = '2020/08/15/aml/';
          this.page.title = '玉山 NLP 應用挑戰賽';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-nobodyzxc-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  

















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"superSample":4,"width":200,"height":400,"position":"right","hOffset":0,"vOffset":-95},"mobile":{"show":true,"scale":1},"react":{"opacity":0.7,"opacityDefault":0.3,"opacityOnHover":0.2},"log":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
